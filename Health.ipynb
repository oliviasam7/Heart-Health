{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e47d65-66ea-4b82-a6b4-dc391b7181bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOGISTIC REGRESSION ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78       102\n",
      "           1       0.76      0.87      0.81       103\n",
      "\n",
      "    accuracy                           0.80       205\n",
      "   macro avg       0.80      0.79      0.79       205\n",
      "weighted avg       0.80      0.80      0.79       205\n",
      "\n",
      "\n",
      "=== RANDOM FOREST (Best) ===\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      "=== XGBOOST ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      "Model + Scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# 1. Import Libraries\n",
    "# ------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. Load & Prepare Data\n",
    "# ------------------------------------------\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"] \n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. Train/Test Split\n",
    "# ------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. Scale Features\n",
    "# ------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames (prevents warnings)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. Train Models\n",
    "# ------------------------------------------\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest + Grid Search\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1\"\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rand_forest = grid_search.best_estimator_\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 6. Evaluate Models\n",
    "# ------------------------------------------\n",
    "print(\"\\n=== LOGISTIC REGRESSION ===\")\n",
    "print(classification_report(y_test, log_reg.predict(X_test_scaled)))\n",
    "\n",
    "print(\"\\n=== RANDOM FOREST (Best) ===\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, best_rand_forest.predict(X_test_scaled)))\n",
    "\n",
    "print(\"\\n=== XGBOOST ===\")\n",
    "print(classification_report(y_test, xgb_model.predict(X_test_scaled)))\n",
    "\n",
    "# ------------------------------------------\n",
    "# 7. Save Model & Scaler\n",
    "# ------------------------------------------\n",
    "joblib.dump(best_rand_forest, \"heart_disease_model.joblib\")\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n",
    "print(\"\\nModel + Scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b5b211-8e40-413c-92ae-201a3fab1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load saved model & scaler\n",
    "model = joblib.load(\"heart_disease_model.joblib\")\n",
    "scaler = joblib.load(\"scaler.joblib\")\n",
    "\n",
    "# Correct feature order\n",
    "FEATURE_COLUMNS = [\n",
    "    \"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\n",
    "    \"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Categorical Encoding Mappings\n",
    "# -----------------------------\n",
    "def encode_inputs(user_input):\n",
    "    return {\n",
    "        \"sex\": 1 if user_input[\"sex\"] == \"Male\" else 0,\n",
    "\n",
    "        \"cp\": {\n",
    "            \"Typical Angina\": 0,\n",
    "            \"Atypical Angina\": 1,\n",
    "            \"Non-Anginal Pain\": 2,\n",
    "            \"Asymptomatic\": 3\n",
    "        }[user_input[\"cp\"]],\n",
    "\n",
    "        \"fbs\": 1 if user_input[\"fbs\"] == \"Yes\" else 0,\n",
    "\n",
    "        \"restecg\": {\n",
    "            \"Normal\": 0,\n",
    "            \"ST-T Abnormality\": 1,\n",
    "            \"Left Ventricular Hypertrophy\": 2\n",
    "        }[user_input[\"restecg\"]],\n",
    "\n",
    "        \"exang\": 1 if user_input[\"exang\"] == \"Yes\" else 0,\n",
    "\n",
    "        \"slope\": {\n",
    "            \"Upsloping\": 0,\n",
    "            \"Flat\": 1,\n",
    "            \"Downsloping\": 2\n",
    "        }[user_input[\"slope\"]],\n",
    "\n",
    "        \"thal\": {\n",
    "            \"Normal\": 1,\n",
    "            \"Fixed Defect\": 2,\n",
    "            \"Reversible Defect\": 3\n",
    "        }[user_input[\"thal\"]],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f00672-3873-4b42-b4d5-784fc6721cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_heart_disease(user_input):\n",
    "    # Encode categorical fields\n",
    "    encoded = encode_inputs(user_input)\n",
    "\n",
    "    # Build a single-row dataframe in correct order\n",
    "    data = pd.DataFrame([[\n",
    "        user_input[\"age\"],\n",
    "        encoded[\"sex\"],\n",
    "        encoded[\"cp\"],\n",
    "        user_input[\"trestbps\"],\n",
    "        user_input[\"chol\"],\n",
    "        encoded[\"fbs\"],\n",
    "        encoded[\"restecg\"],\n",
    "        user_input[\"thalach\"],\n",
    "        encoded[\"exang\"],\n",
    "        user_input[\"oldpeak\"],\n",
    "        encoded[\"slope\"],\n",
    "        user_input[\"ca\"],\n",
    "        encoded[\"thal\"]\n",
    "    ]], columns=FEATURE_COLUMNS)\n",
    "\n",
    "    # Scale the input\n",
    "    data_scaled = scaler.transform(data)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(data_scaled)[0]\n",
    "    probability = model.predict_proba(data_scaled)[0][1]\n",
    "\n",
    "    return prediction, probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793b035-895f-4428-9036-0c8e101aa609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
